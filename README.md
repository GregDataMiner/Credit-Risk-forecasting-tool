![Interface de l'application](Images/image3.png)

## ğŸŒ ğŸ”¥ **Testez l'application en direct !** ğŸ”¥ ğŸŒ  

ğŸ”— **[CLIQUEZ ICI POUR ESSAYER L'APPLICATION](https://credit-risk-forecasting-tool-ogqsechcb4bggnkcieflat.streamlit.app/)**  

---

## ğŸ“Œ Description
Ce projet est une application de prÃ©diction du risque de crÃ©dit permettant dâ€™Ã©valuer si un prÃªt est **accordÃ© ou refusÃ©** en fonction du profil de lâ€™emprunteur.  
Lâ€™application utilise un modÃ¨le **XGBoost** entraÃ®nÃ© sur un dataset de prÃªts et est dÃ©ployÃ©e avec **Streamlit**.

### ğŸ“Š CaractÃ©ristiques principales :
âœ”ï¸ **ModÃ¨le XGBoost** pour une classification binaire du risque de dÃ©faut.  
âœ”ï¸ **Encodage OneHot** des variables catÃ©gorielles pour un traitement efficace.  
âœ”ï¸ **Normalisation** des variables numÃ©riques avec StandardScaler.  
âœ”ï¸ **Interface interactive** avec Streamlit pour tester diffÃ©rents profils emprunteurs.  
âœ”ï¸ **Prise en charge de nouvelles observations** sans nÃ©cessiter de rÃ©entraÃ®nement du modÃ¨le.  


## ğŸ¯ Utilisation

### 1ï¸âƒ£ Lancer l'application Streamlit
#### Une interface sâ€™ouvre dans le navigateur permettant de tester diffÃ©rents profils emprunteurs.
#### L'application utilise le modÃ¨le le plus adaptÃ© parmi une quinzaine de modÃ¨le
![Interface de l'application](Images/image1.png)
#### Elle donne snsuite un avis sur le risque de dÃ©faut de l'emprunteur et accorde le prÃªt ğŸ’¸ ou non âŒ
![Interface de l'application](Images/image2.png)
#### Une partie qui affiche l'importance de chaque parametre permet Ã  l'utilisateur de savoir sur quoi jouer pour faire basculer la dÃ©cision en sa faveur 

## ğŸ— Structure du projet
```bash
Credit-Risk-forecasting-tool/
â”‚â”€â”€ data/                       # Dossier contenant le dataset d'entraÃ®nement
â”‚â”€â”€ models/                     # Dossier contenant les fichiers modÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ xgboost_credit_risk.pkl  # ModÃ¨le XGBoost entraÃ®nÃ©
â”‚   â”œâ”€â”€ onehot_encoder.pkl       # OneHotEncoder sauvegardÃ©
â”‚   â”œâ”€â”€ scaler.pkl               # StandardScaler sauvegardÃ©
â”‚â”€â”€ images/                      # Dossier contenant les images du projet
â”‚â”€â”€ streamlit_app.py             # Code de l'application Streamlit
â”‚â”€â”€ train_model                  # Script pour entraÃ®ner le modÃ¨le
â”‚   â”œâ”€â”€ train_model.py           # format py
â”‚   â”œâ”€â”€ train_model.ipynb        # format jupyther notebook
â”‚â”€â”€ save_models.ipynb            # Script pour sauvegarder le meilleur modÃ¨le
â”‚â”€â”€ requirements.txt             # DÃ©pendances nÃ©cessaires
â”‚â”€â”€ README.md                    # PrÃ©sentation du projet
```

le code qui m'a permi de traiter les donnÃ©es et comparer tous les modÃ¨les de ML est [ici](train_model/train_model.ipynb)

les donnÃ©es sont disponibles [ici](data/credit_risk_dataset.csv)


---

## ğŸ”¬ DÃ©tails techniques

### ğŸ“Œ ModÃ¨le de Machine Learning
- `XGBoostClassifier` pour une classification binaire (`1` = dÃ©faut, `0` = remboursement rÃ©ussi).
- **HyperparamÃ¨tres :**
  - `max_depth=6`
  - `learning_rate=0.1`
  - `n_estimators=100`
  - `eval_metric='logloss'`

### ğŸ“Œ PrÃ©processing
- **Visualisation des donnÃ©es** avec **Seaborn**
![corr](Images/corr.png)
![grade](Images/grade.png)
![home](Images/home.png)
![intent](Images/intent.png)

- **Encodage** des variables catÃ©gorielles avec **OneHotEncoder**
```bash
from sklearn.preprocessing import OneHotEncoder
import numpy as np
import pandas as pd

# CrÃ©ation de l'encodeur OneHotEncoder
ohe = OneHotEncoder()

# Apprentissage des catÃ©gories uniques pour chaque colonne catÃ©gorielle dans x_train
ohe.fit(x_train[ohe_colums])

# Affichage des catÃ©gories apprises par l'encodeur pour chaque colonne catÃ©gorielle
ohe.categories_

# Fusion des catÃ©gories de toutes les colonnes encodÃ©es en un seul tableau numpy
# Cela permet d'obtenir toutes les valeurs uniques transformÃ©es en colonnes aprÃ¨s One-Hot Encoding
merge_ohe_col = np.concatenate((
    ohe.categories_[0],  # CatÃ©gories uniques de la premiÃ¨re colonne
    ohe.categories_[1],  # CatÃ©gories uniques de la deuxiÃ¨me colonne
    ohe.categories_[2],  # CatÃ©gories uniques de la troisiÃ¨me colonne
    ohe.categories_[3],  # CatÃ©gories uniques de la quatriÃ¨me colonne
    ohe.categories_[4],  # CatÃ©gories uniques de la cinquiÃ¨me colonne
    ohe.categories_[5],  # CatÃ©gories uniques de la sixiÃ¨me colonne
    ohe.categories_[6]   # CatÃ©gories uniques de la septiÃ¨me colonne
))
# Affichage des noms de colonnes aprÃ¨s encodage
merge_ohe_col  

# Transformation des donnÃ©es d'entraÃ®nement en one-hot encoding et conversion en DataFrame
ohe_data = pd.DataFrame(
    ohe.transform(x_train[ohe_colums]).toarray(),  # Transformation en tableau numpy
    columns=merge_ohe_col  # Attribution des colonnes selon les catÃ©gories fusionnÃ©es
)

# Transformation des donnÃ©es de test en one-hot encoding et conversion en DataFrame
ohe_data2 = pd.DataFrame(
    ohe.transform(x_test[ohe_colums]).toarray(),  # Transformation en tableau numpy
    columns=merge_ohe_col  # Attribution des colonnes selon les catÃ©gories fusionnÃ©es
)

```

- **Normalisation** des variables numÃ©riques avec **StandardScaler**
```bash
scaler_normal = StandardScaler()
X_new.loc[:,normal_col] = scaler_normal.fit_transform(X_new.loc[:,normal_col])
X_new_test.loc[:,normal_col] = scaler_normal.transform(X_new_test.loc[:,normal_col])

```

- **CrÃ©ation de nouvelles features**
```bash
# crÃ©e ratio loan-to-income
data['loan_to_income_ratio'] = data['loan_amnt'] / data['person_income']

# crÃ©e ratio loan-to-employment length
data['loan_to_emp_length_ratio'] =  data['person_emp_length']/ data['loan_amnt'] 

# crÃ©e ratio interest rate-to-loan amount 
data['int_rate_to_loan_amt_ratio'] = data['loan_int_rate'] / data['loan_amnt']

```
- **Sauvegarde la pipeline complÃ¨te (prÃ©processing + modÃ¨le) et classement des modÃ¨le testÃ©s**  avec **PyCaret et AutoGluon**

![classementf](Images/classement_f.png)

1ï¸âƒ£ Meilleur score test (0.9380) : Il surpasse les autres modÃ¨les en termes de prÃ©cision.
2ï¸âƒ£ Fit Order Ã©levÃ© (11) : Cela signifie qu'il a Ã©tÃ© entraÃ®nÃ© dans les Ã©tapes avancÃ©es de l'AutoML, ce qui montre qu'AutoGluon l'a identifiÃ© comme performant et a affinÃ© ses hyperparamÃ¨tres.
3ï¸âƒ£ Gagne face Ã  CatBoost et LightGBM : MÃªme si CatBoost et LightGBM sont trÃ¨s performants, XGBoost a une meilleure gÃ©nÃ©ralisation sur les donnÃ©es de test.

--- 


## ğŸ“ Contact

ğŸ‘¤ **Auteur** : GrÃ©goire
ğŸ“§ **Email** : sarsat.gregoire@gmail.com  
ğŸŒ **LinkedIn** : [mon profil Linkedin](https://www.linkedin.com/in/gregoire-sarsat/)

ğŸŒŸ **Si tu trouves ce projet utile, nâ€™hÃ©site pas Ã  laisser une â­ sur GitHub !** ğŸš€ğŸ‰

